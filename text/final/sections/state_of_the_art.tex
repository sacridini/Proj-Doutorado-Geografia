\begin{titlepage}
    \centering
    \vspace*{\fill}
    
    \vspace*{0.5cm}
    
    \Large% \bfseries
    Capítulo 1

    \vspace*{1cm}

    \Large% \bfseries
    Perspectivas sobre a Utilização de Algoritmos para o Processamento de Séries Temporais no Estudo de Distúrbios Florestais

    \vspace*{5cm}

    % \large Eduardo Ribeiro Lacerda

    \vspace*{\fill}
\end{titlepage}

\section{Perspectivas sobre a Utilização de Algoritmos para o Processamento de Séries Temporais no Estudo de Distúrbios Florestais}

\subsection{Introdução}

\hspace{13pt} A necessidade da incorporação do tempo como variável chave em estudos geográficos se deu inicialmente a partir da década de 1960/1970 no campo teórico \citep{gregory85} como uma promessa para a melhor compreensão da dimensão espacial dos processos. Na prática, esta incorporação acabou se dando de forma bastante limitada devido a dificuldade de acesso a séries históricas confiáveis, assim como pela dificuldade de manipulação das mesmas, quase sempre através de um ambiente computacional também limitado. Por décadas, houve uma predominância na ausência de políticas voltadas para o estabelecimento de ações sistemáticas voltadas para o acúmulo de dados em órgãos públicos e empresas do governo, assim como para a criação de programas de monitoramento. Até então, poucas eram as bases disponíveis para além do censo do IBGE, como o PRODES, exceção desenvolvida pelo INPE ainda na década de 1980.

A partir da década de 1990 com o desenvolvimento da internet, da capacidade e barateamento do hardware e do amadurecimento no desenvolvimento de softwares pela comunidade científica, a utilização de métodos computacionais na análise de dados científicos se tornou cada vez mais presente e com uma maior possibilidade de acesso não só a grandes bases de dados como também a ambientes computacionais de alto desempenho. Inicialmente o acesso ainda possuía algumas limitações como a alta concorrência pelo uso de poder computacional disponível e de tráfego de dados através de projetos e editais, mas logo se tornou descentralizado quando muitos projetos puderam ser realizados em \textit{workstations}. Ainda sim, havia uma dependência física da disponibilidade de acesso a estas estruturadas através de centros universitários normalmente localizados em grandes centros urbanos e quase sempre nos países desenvolvidos.

Já nos anos 2000 e 2010 com o estabelecimento da internet como meio oficial de comunicação do corpo científico global através da digitalização dos periódicos, assim como a padronização dela como meio de acesso a bases de dados abertas, parte significativa da comunidade científica passa então a interagir de forma mais integrada ao criar padrões de armazenamento de dados. O aumento da percepção popular sobre o uso de dados acumulados através do uso diário das redes sociais significou também uma percepção quase senso comum sobre a importância do armazenamento de dados ao longo do tempo e também da abertura e transparência sobre dados com características temporais intrínsecas.

Muitas bases de dados importantes tradicionalmente fechadas e com valores de acesso proibitivos para o grande público passaram a disponibilizar todo o acervo de forma gratuita como o caso das imagens do satélite Landsat. A democratização do acesso aos dados é sem dúvida de extrema importância para o desenvolvimento científico global e fica ainda mais evidente quando programas como o do satélite Landsat comprovam o aumento exponencial na produção de trabalhos científicos que passaram a utilizar as imagens desde a liberação \citep{ZHU2019382, WULDER2019127, WULDER20122}. No entanto, o acesso ao poder computacional para processar essa quantidade enorme de dados agora disponível ainda se restringia quase sempre a instituições que já possuíam recurso disponível. Foi somente a partir da segunda metade da década de 2010 que opções baseadas no conceito de computação em nuvem/computação elástica passaram a surgir como uma solução para a falta de capacidade computacional enfrentada por pesquisadores em atuação em instituições de orçamento reduzido. Isso representou uma mudança significativa para pesquisadores de países onde o acesso as estruturas científicas quase sempre se deu de forma mais limitada. 

As consequências dessas novas possibilidades vem gerando não só um aumento ainda maior na quantidade total da produção acadêmica global como também na elaboração de estudos com uma visão descentralizada dos grandes centros de pesquisas já consagrados. Não somente estudos sobre o próprio território, como estudos em escala global que anteriormente eram quase sempre liderados somente pelos mesmos grupos de pesquisa e agora podem ser desenvolvidos por cabeças pensantes no sul global \citep{ArribasBel2018}.

% Carla:
% Acho importante ter um item de estado da arte sobre monitoramento da MA. Complexidades, fragilidades das ações. O que não é coberto e demanda outras ações.
% Trazer questões clássicas que definem está complexidade, como: relevo, fragmentação, diversidade…

Devido aos avanços citados, a utilização de séries temporais para a análise espaço-temporal da paisagem tem surgido com maior força nos últimos anos como consequência dessa evolução histórica. A aplicação dessas técnicas é da mais diversa possível, vindo inicialmente quase que exclusivamente dos estudos econométricos e de poucas outras áreas científicas para a sua massificação em muitas outras áreas. Uma delas, e que será abordada neste trabalho é a utilização de técnicas de análise de séries temporais em imagens digitais orbitais com o intuito de analisar perdas e ganhos de vegetação em áreas naturais florestadas. Esse tipo de aplicação vem ganhando força não só pelo entendimento das mudanças da paisagem e suas dinâmicas, como também pela necessidade de entender estes processos no tempo para melhor detectar eventos e monitorar a degradação e a recuperação da paisagem, sejam eles naturais ou antrópicos.

Tanto a análise quanto o monitoramento do uso do solo nunca tiveram tanta importância como hoje devido ao maior entendimento e comprometimento internacional em relação as variáveis influenciadoras do processo da mudanças climáticas através de tratados e acordos de estimulo à conservação e restauração de áreas naturais \citep{ALMEIDA201934}, entendendo ainda o protagonismo da análise espacial e do monitoramento por satélites como ferramenta essencial neste processo \citep{WHITE2019}. 

Políticas de REDD+, assim como vários esforços de cooperação internacional como os propostos pelo Bonn Challenge e os Aichi Targets deficidos pela CDB (\textit{Convention on Biological Diversity}), tem como ferramenta principal a incorporação de técnicas de sensoriamento remoto para o monitoramento do cumprimento dos objetivos, sendo então diretamente vinculados ao entendimento do comportamento da paisagem no tempo \citep{BOS2019295, CROUZEILLES2019}. Estudos mais recentes vem demonstrando que os processos de degradação em florestas tropicais tem impacto similar ou até mesmo maior em relação as emissões de carbono que o desmatamento das mesmas \citep{Harris1573, Houghton2012, Grace2014}. É importante notar aqui que a utilização do termo distúrbio é diferente do de degradação. Enquanto distúrbio está associado a um único evento que pode ser tanto natural como antrópico, degradação se associa a um processo temporalmente maior de perda de biomassa e a um tipo de influência necessariamente antrópica se considerarmos a definição do IPCC (\textit{Intergovernmental Panel on Climate Change}) ou não necessariamente antrópica caso se considere a definição da FAO (\textit{Food and Agriculture Organization of the United Nations}) \citep{Hirschmugl2017}. 

Além disso, outros estudos demonstram que as florestas tropicais tem sofrido mais pressões do que as temperadas. Um terço das florestas tropicais já foram perdidas para o desmatamento, e da área restante, 46\% da área está fragmentada, 30\% degradada e apenas 24\% ainda permanece em estado mais preservado \citep{Hirschmugl2017}. Sabendo disso, fica ainda mais clara a necessidade de entender quais as melhores técnicas que podem ser utilizadas para o monitoramento destes processos \citep{Hirschmugl2017}. 

O momento político em relação a perspectiva da preservação do meio ambiente em que estamos inseridos necessita ainda mais que as pesquisas de compreensão e mapeamento de distúrbios sejam realizadas de forma cada vez mais transparente e acessível a todos para que processos de degradação sejam detectados a tempo. Apesar da importância inquestionável dos projetos de monitoramento, a análise dos processos no tempo através do mapeamento dessas áreas poderá contribuir ainda mais para um entendimento mais profundo sobre os porquês. Isso representa uma melhora qualitativa das análises sobre a paisagem. Pensando nisso, é importante entendermos quais tecnologias estão disponíveis e quais as possibilidades de mapeamento são possíveis, tendo como objetivo principal entender não só suas potencialidades como suas limitações.

Sendo assim, este trabalho tem como objetivo a apresentação e análise das características dos principais algoritmos de detecção de distúrbios, principalmente os especializados na detecção de mudanças em áreas florestadas, seja na perda como no ganho de biomassa.

\subsection{Breve Histórico}

\hspace{13pt} Estudos espaçotemporais com o objetivo de detecção de mudanças não são novos na área do sensoriamento remoto. A tradicional análise bi-temporal de dados previamente classificados ainda é presente em muitos estudos atuais. No entanto, esse tipo de estudo tende a conter um número maior de erros, já que quanto maior o número de imagens analisadas, maior a quantidade de mapas com erros de classificação associados que serão levados em consideração. De qualquer forma, estes tipos de estudos tendem a ser o que possuem menor requisito de poder computacional, já que necessitam apenas de operações simples entre álgebra de bandas.

Com o tempo, o maior poder computacional disponível não só para o processamento como para o armazenamento de dados possibilitou que outras técnicas mais elaboradas pudessem ser implementadas, onde ao invés de apenas algumas imagens serem consideradas, todas as imagens da série temporal são levadas em consideração. Isso possibilitou também que muitas técnicas de análise de séries temporais tipicamente aplicadas principalmente na área de econometria pudessem ser utilizadas em estudos geoespaciais.

O processamento de imagens de satélite que historicamente sempre foi feito através do processamento de pixels individuais, passou a partir da década de 2000 a ser feita em muitos casos através do delimitação de objetos com a popularização das imagens de alta-resolução espacial e consequentemente das técnicas de GEOBIA (\textit{Geographic Object-Based Image Analysis}). As análises pixel à pixel que pareciam estar cada vez mais em desuso, acabaram ressuscitando nos últimos anos devido a capacidade de processamento de séries temporais densas. A densidade da série é um ponto chave para esse retorno, já que para que a análise temporal seja bem sucedida e para que os algoritmos aplicados possam entender ainda melhor os processos ocorridos no tempo, é necessário que os dados utilizados tenham resolução temporal condizente com o que se quer detectar. No caso da utilização de imagens de satélite isso se torna um limitador importante, já que a disponibilidade de satélites imageadores historicamente nunca foi alta e tem custo extremamente elevado quando comparado a outros tipos de sensores. Outro problema é que os satélites possuem um tempo de revisita que em muitos casos não possibilitam que uma série mais densa possa ser estruturada. 
%\par
Além disso, problemas como a presença de nuvens, assim como ruídos na própria imagem e a heterogeneidade da distribuição solar no planeta e sua interação com o relevo dificultam ainda mais esse processo ao criar sombras. No entanto, com o tempo, outros satélites foram sendo desenvolvidos e propositalmente pensados com o objetivo de incorporar as séries de imagens já existentes derivadas de projetos antigos com os recém lançados. Um exemplo disso foi o lançamento da série Sentinel 2 (A e B) pela Agência Espacial Europeia com resoluções espectrais e espaciais similares às encontradas na série Landsat, o que possibilita uma fusão entre imagens de satélites diferentes com o objetivo de aumentar a densidade de imagens. Com isso, tanto a disponibilidade de dados como a resolução temporal dos satélites ganharam nova relevância. A disponibilização de imagens de forma gratuita, assim como a preocupação com a manutenção de séries históricas e o desenvolvimento de constelações que diminuam a resolução temporal acabaram possibilitando esse retorno do pixel como chave analítica central no sensoriamento remoto.


\subsection{Técnicas e Algoritmos para a Análise Temporal de Áreas Florestadas}
\hspace{13pt} Analisar áreas florestadas sob uma perspectiva temporal possibilita a identificação de processos e padrões que uma simples caracterização espectral mais tradicional não é possível de identificar devido a limitações ligadas a resolução espacial, radiométrica e espectral. Sendo assim, ao incluir a dimensão temporal, é possível entender dinâmicas como a supressão da floresta em um dado momento, assim como também os distúrbios naturais e degradações de origem antrópica ao longo do tempo.
A degradação associada ao desmatamento e posterior uso agrícola da terra, seguido do abandono e consequente retorno da vegetação através de processos de regeneração natural, ou então um processo de degradação mais lento, como a extração seletiva de madeira, são exemplos de mudanças no uso e cobertura da terra que só podem ser compreendidos através de técnicas como as que serão mostradas neste trabalho. 

Técnicas de detecção de mudança possuem uma longa história na área de sensoriamento remoto. Desde as primeiras aplicações utilizando sensores TM do satélite Landsat 5 na década de 1980 e 1990, muitos estudos foram feitos. Inicialmente os estudos visavam majoritariamente a aplicação de técnicas mais tradicionais como o mapeamento das áreas de interesse utilizando técnicas de classificação de imagens tanto de forma supervisionada como não supervisionada e posterior cálculo da diferença entre duas ou mais imagens. Neste caso, somente métricas como ganho e perda de área e sua consequente espacialização poderiam ser extraídas e visualizadas. No entanto, com o aumento do poder computacional e consequente amadurecimento das técnicas, softwares e bibliotecas disponíveis, o processamento de dados multi-temporais passaram a ser entendidos em sua totalidade. Ou seja, com a aplicação de técnicas menos reducionistas. O que isso significa na prática é que a análise de mudanças de áreas de floresta passou a ser feita através da manipulação tanto da criação de composições anuais, assim como intra-anuais e também da análise de toda a série temporal sem maiores cortes.

Para o processamento de séries temporais utilizando imagens de satélite é necessário se preocupar também com o pré processamento das mesmas para que a aplicação do algoritmo, seja ele qual for, não influencie o resultado final com ruídos derivados de falta de calibração geométrica entre as imagens de diferentes datas, assim como a variação radiométrica, além da presença de possíveis sombras. Para isso, é necessário utilizar técnicas de pré-processamento como a ortorretificação e a correção radiométrica (atmosférica) das imagens. Dependendo do satélite utilizado é possível utilizar métodos implementados pela própria agência distribuidora, o que é bastante recomendado. No caso da correção geométrica das imagens, muitas já são disponibilizadas após serem tratadas automaticamente por método de correção subpixel \citep{Gutjahr2014}. Já para a correção radiométrica existem dois tipos: as calibração absoluta e a relativa. A absoluta faz a calibração transformando os valores digitais em valores físicos de superfície e aplicando algoritmos como o 6S \citep{Sagan2004}, já a calibração relativa utiliza uma imagem de referência como base e aproxima os valores do resto da série de acordo com a imagem base. Trabalhos comparando os dois métodos já foram desenvolvidos utilizando imagens Landsat e apresentam resultados similares \citep{Chen2010}. Produtos da série Landsat ainda possuem métodos internos de correção além de máscaras para a filtragem de nuvens, sombras e outras características das imagens \citep{ZHU2015269, ZHU201283, Huang2010}, o que facilita bastante a etapa de pré-processamento.

Alguns algoritmos foram sendo desenvolvidos ao longo dos últimos anos com o objetivo de lidar melhor com essas séries. Um dos mais tradicionais é o BFAST \sloppy  \citep{VERBESSELT2010106, VERBESSELT20102970, VERBESSELT201298} que possui uma versão visando dados espaciais denominada bfastSpatial \citep{bfastSpatial}. As duas ferramentas possuem o mesmo algoritmo de detecção, mas a versão espacial se diferencia por conta de uma série de funções voltadas para facilitar o pré-processamento dos dados com o intuito de construir inicialmente a série temporal. A construção das séries temporais em ambiente offline sem ajuda de ferramentas mais modernas é, de fato, bastante trabalhosa e contém muitas etapas necessárias para que a análise final possa ser feita sem maiores problemas e sem a geração de ruídos por conta de dados de entrada problemáticos. É importante notar também que as duas ferramentas, diferentemente de outros algoritmos que serão analisados neste trabalho, não são voltados exclusivamente para a detecção de distúrbios em ambientes florestais,  mas sim em basicamente qualquer outro tipo de uso. No entanto, o uso das duas ferramentas em ambientes florestais é provavelmente o mais comum entre os trabalhos existentes. 

O BFAST tem como ideia geral analisar a série temporal de imagens analisando os valores pixel à pixel e detectar quebras (\textit{breakpoints}) de pixels que tenham valor discrepante do valor médio esperado. É possível detectar mais de uma quebra em uma mesma série de pixels, o que é interessante principalmente para análise de usos agrícolas, assim como quando comparados a áreas florestais. O algoritmo ainda pode ser utilizado em objetos, como apresentado por Siti Latifah \citep{LATIFAH2016}, onde a integração com técnicas de GEOBIA apresentou ótimos resultados. Este resultado demonstra ainda um novo potencial a ser explorado, onde a integração de dois paradigmas (pixel/objeto) através do processamento de séries temporais pode trazer novas formas de análise e até mesmo a implementação de novos algoritmos.

Já outros trabalhos utilizando o BFAST demonstraram a capacidade do mesmo na detecção de quebras para a caracterização de distúrbios cíclicos em florestas com o objetivo de explicar mudanças estruturais que acabam influenciando diretamente na qualidade da floresta presente e não só na sua simples presença ou não presença \citep{JAKOVAC2017, DUTRIEUX2016112}.

Mais recentemente, o BFAST passou por um processo de reimplementação, deixando a linguagem R de lado como em sua versão original e sendo totalmente reprogramado utilizando a linguagem Python. Essa mudança se deu pela fato da nova versão possuir uma integração direta com a biblioteca de processamento paralelo OpenCL, o que garantiu uma diminuição no tempo total de processamento em duas ordens de grandeza \citep{Gieseke2020}. Por utilizar um padrão aberto de paralelismo, a nova implementação possui a capacidade de poder se beneficiar do paralelismo independente do tipo e do fabricante do hardware, podendo ser paralelizado tanto na CPU (Intel/AMD) quando na GPU (Nvidia, AMD, Intel).

Além do BFAST, outras implementações computacionais foram desenvolvidas com o objetivo de analisar séries temporais para detecção de padrões em tipos variados de uso do solo. Este é o caso do Timesat \citep{Jnsson2004TIMESATA}. O Timesat, apesar de ter a aplicação mais voltada para a caracterização de tipos de culturas agrícolas através da interpretação da série, também possui uso na caracterização de tipos e também de distúrbios em florestas \citep{Wenbo2017}. O Timesat ainda possui diversas ferramentas internas para o tratamento de ruídos, tratamento de dados faltantes e composição de séries sazonais utilizando algoritmos como o Savitzky-Golay \citep{Savitzky1964}.

Ao aprofundarmos mais, para além das técnicas mais tradicionais, podemos entender que esses algoritmos apresentados, assim como muitos outros existentes se diferenciam entre si. Além disso, alguns acabam sendo desenvolvidos como algoritmos especialistas na aplicação de detecção de distúrbios em florestas, ao contrário dos algoritmos já citados. Esses novos métodos de análise ainda podem ser categorizados em quatro sub-categorias: algoritmos baseados na detecção de mudanças baseados em limiares, os baseados em ajude de curvas, os baseados no ajude de trajetórias e os baseados na segmentação de trajetórias \citep{Banskota2014, Hirschmugl2017}.

\subsection{Detecção de Mudanças Baseada em Limiares}
\hspace{13pt} Os métodos de detecção baseados em limiares funcionam buscando a diferenciação de áreas de floresta e não floresta, e posteriormente separando áreas de floresta "intacta" das que sofreram algum tipo de distúrbio ou processo de degradação. A ideia é utilizar uma série temporal previamente tratada formadas tanto puramente por índices de vegetação, como pela integração de diversas bandas espectrais e bandas sintéticas derivadas de estatísticas da própria série. Esses métodos possuem um grande potencial e aplicação, mas ao mesmo tempo tem como ponto negativo a necessidade da delimitação empírica de limiares, o que dificulta bastante a replicabilidade dos trabalhos.

\subsection{Detecção de Mudanças Baseada no Ajuste de Curvas}
\hspace{13pt} A utilização de métodos baseados no ajuste de curvas em áreas florestadas tem como objetivo entender o comportamento espectral primeiramente aplicando uma linha de regressão, onde, dependendo da inclinação da mesma, é possível detectar a presença ou ausência de mudanças significativas. Além disso, o sinal da inclinação determina também o ganho ou perda de biomassa. O lado negativo desse método é a necessidade da suposição de uma certa normalidade entre os dados de entrada, o que em sensoriamento remoto é quase sempre muito difícil de se obter. Isso já tende a limitar a aplicação de métodos como esse a sensores com menor resolução temporal como os presente no projeto MODIS (\textit{Moderate-Resolution Imaging Spectroradiometer}), ou então de composições muito bem estruturadas de sensores como o Landsat. A utilização desse método pode ser exemplificada pelo trabalho desenvolvido no bioma amazônico utilizando imagens MODIS onde é demonstrado a relação entre o corte seletivo e a mudança da resposta fenológica da vegetação na região ao longo do tempo \citep{KOLTUNOV20092431}.

\subsection{Detecção de Mudanças Baseada no Ajuste de Trajetórias}
\hspace{13pt} As técnicas de ajuste de trajetórias se diferenciam das anteriores por analisarem as mudanças a partir de trajetórias idealizadas. Através da aplicação de métodos comparativos (ajuste) entre a série estudada com a de referência, seja através do cálculo da distância euclidiana como pela utilização de métodos mais complexos como o DTW (\textit{Dynamic Time Warping}) \citep{VELICHKO1970223, SakoeChiba71, Berndt1994} ou sua versão para a classificação de uso do solo, o TWDTW (\textit{Time-Weighted Dynamic Time Warping}) \citep{Maus2016, Maus2019}, o ajuste de trajetórias funciona como um método de análise supervisionado já que depende de amostras de "treino" para a obtenção de resultados satisfatórios.

Este tipo de algoritmo, devido a sua natureza de carácter supervisionado, tem sido utilizado principalmente em estudos aplicados na tipificação de culturas agrícolas, onde a diferenciação dos alvos só pode ser feita utilizando conhecimentos relativos ao comportamento espectral do alvo no tempo. Este tipo de algoritmo necessita de uma densidade de imagens maior que as outras técnicas, já que é necessário o maior grau possível de precisão na série para encaixar e detectar as características entre as duas séries. Para este tipo de aplicação são utilizadas normalmente imagens derivadas do sensor MODIS, devido a sua resolução temporal e as suas aplicações na caracterização do comportamento espectral de grandes áreas agrícolas, onde a resolução espacial das bandas do visível e NIR, mais usadas na elaboração de índices, apresentam resolução de 250m. É possível utilizar imagens Landsat com este método, mas é necessário acumular uma grande densidade de imagens através da fusão do histórico de vários sensores e/ou trabalhando com área de interseção entre path/row diferentes, o que limita sua aplicação \citep{Bendini2016}. Além dessas limitações, outros desafios vem sendo enfrentados em relação à dificuldade de detecção de distúrbios pontuais de corte seletivo e posterior regeneração natural do local, já que amostras muito bem definidas para este tipo de distúrbio precisam ser coletadas. No entanto, exemplos de aplicação em florestas tropicais são presentes \citep{Hirschmugl2013, KENNEDY2007370}.


\subsection{Detecção de Mudanças Baseado na Segmentação de Trajetórias}
\hspace{13pt} O método de segmentação de trajetórias pode ser exemplificado pelo algoritmo Landtrendr \citep{KENNEDY20102897, KENNEDY2012117}, que funciona dividindo a série temporal em segmentos para posterior classificação. Este tipo de abordagem favorece estudos onde o objetivo não está somente na quantificação de eventos de grande impacto e mudança, mas também na qualificação desses eventos. Com este tipo de algoritmo é possível não só a detectar distúrbios imediatos (provável evento de desmatamento), como em detectar de distúrbios de longo prazo (possível processo de degradação/corte seletivo/praga), assim como processos de regeneração/recuperação de longa duração (regeneração natural) e de curto prazo (floresta plantada e projetos de reflorestamento). Os segmentos são divididos a partir da identificação de vértices ao longo da série. Os vértices representam os pontos da série onde ocorreram algum tipo de mudança na qual o algoritmo considerou relevante. A escolha da relevância para a criação de um vértice (quebra) é feita de acordo com regras pré-definidas pelo usuário. Outra vantagem desse método é a possibilidade de análise sem a necessidade de amostras de eventos exemplo como no caso dos algoritmos de ajustes de trajetórias.
No entanto, o método de segmentação de trajetórias também possui suas desvantagens. Uma delas é que algoritmo tende a  desconsiderar efeitos sazonais da vegetação, apesar da possibilidade de ajuste da série através da utilização de limiares de relevância para consequente suavização. Além disso, é um método que ainda possui poucos trabalhos que aplicam o métodos em florestas tropicais, sendo em sua maioria aplicados à áreas temperadas \citep{PFLUGMACHER2012146, Griffiths2015}.

\subsection{Exemplos de Técnicas e suas Características}
\hspace{13pt} Além do BFAST e de outros algoritmos/softwares apresentados previamente, podemos listar brevemente alguns outros algoritmos de detecção automática de mudanças. É importante notar que alguns desses na verdade não realizam exatamente o trabalho de detecção da mudança, mas sim mais um processo de predição dessas mudanças, já que trabalham a partir de técnicas de regressão. Algumas características e particularidades de cada algoritmo também serão apresentadas. Todos foram desenvolvidos nos últimos anos e representam grande parte dos métodos de detecção automática de distúrbios presentes na literatura recente. São eles: 

\begin{itemize}
  \item \textbf{CCDC} - \textit{Continuous Change Detection and Classification} \citep{ZHU2014152} - O CCDC apresenta funções de análise de séries temporais utilizando não composições anuais ou intra-anuais, mas sim toda a série de imagens de entrada sem a necessidade de intervalos constantes, o que o difere da maioria dos algoritmos exemplificados aqui. O CCDC funciona apenas com imagens sem a presença de nuvens e sombra e busca encontrar padrões de sazonalidade, tendências e quebras na série. Uma característica interessante do CCDC é que o algoritmo é capaz de gerar imagens "sintéticas" para qualquer data presente na série de entrada \citep{ZHU201567}. Estas imagens sintéticas geradas são utilizadas obrigatoriamente como dado de entrada por algoritmos como o MIICA e o ITRA e também podem ser utilizadas opcionalmente por algoritmos como o Landtrendr e o VCT, ao invés de utilizar as imagens originais com valores de reflectância da superfície. O CCDC é utilizado para a detecção de eventos de grande magnitude, sendo limitado para a detecção de processos de degradação, por exemplo. No entanto, pode ser utilizado na detecção de mudanças de vários tipos de uso do solo e não somente na deteccão de distúrbios florestais.
  
  \item \textbf{COLD} - \textit{Continuous Monitoring of Land Disturbance} \citep{Cohen2020} - O COLD é baseado no CCDC com o objetivo de melhorar a detecção de distúrbios florestais. Diferente do CCDC que detecta mudanças baseadas em eventos de grande diferença espectral, o COLD possui a capacidade de detecção de mudanças mais sutis, o que lhe garante suprir essa deficiência presente no CCDC.
  
  \item \textbf{LandTrendr} \citep{KENNEDY20102897, KENNEDY2012117} - O Landtrendr, desenvolvido pelo Environmental Monitoring, Analysis and Process Recognition Lab da Universidade de Oregon, também trabalha tanto com composições de imagens com valores de reflectância da superfície como com imagens sintéticas geradas pelo CCDC. O algoritmo necessita que as imagens não possuam interferência de nuvens e sombras e gera seus dados de saída através da aplicação da técnica de segmentação de trajetórias. O Landtrendr pode gerar saídas como métricas tanto para distúrbios de perda como de ganho, além de detectar se as mudanças ocorreram de forma lenta ou rápida, possibilitando também o cálculo da duração dos eventos segmentados previamente gerando não só dados contínuos como a magnitude, assim como dados discretos como a duração e o ano da detecção. É certamente um dos algoritmos com maior quantidade de informação gerada por rodada, o que facilita muito sua utilização. Outra vantagem do Landtrendr é que apesar de ter sido implementado inicialmente utilizando a linguagem de programação proprietária IDL em um ambiente bastante complicado de manuseio através do software ENVI, foi recentemente implementado diretamente na plataforma online Google Earth Engine \citep{GORELICK201718}, o que veio a facilitar e muito sua utilização pela comunidade \citep{Kennedy2018}. A conversão do algoritmo para a plataforma online do Google possibilitou ainda que o tempo de processamento do mesmo fosse reduzido significativamente. No entanto, a plataforma parece restringir o processamento para uma área equivalente a de uma imagem Landsat por vez. Ou seja, para a aplicação do algoritmo para áreas maiores é necessário dividir o processamento em segmentos menores.
  
  \item \textbf{VCT} - \textit{Vegetation Change Tracker} \citep{Huang2010, THOMAS201119} - O VCT utiliza composições sem nuvem de imagens com valor de reflectância da superfície, ou de composições sintéticas geradas pelo algoritmo CCDC e extrai uma métrica de similaridade a áreas de floresta intacta. O algoritmo prediz os distúrbios detectando padrões que se afastam da métrica de similaridade.
  
  \item \textbf{EWMACD} - \textit{Exponentially Weighted Moving Average Change Detection} \citep{Brooks2014} - Este algoritmo foi desenvolvido com o objetivo de detectar apenas distúrbios florestais ao analisar o resíduo entre o pixel observado e os valores derivados de uma predição gerado por um processo de regressão harmônica \citep{Brooks2012}. Além disso, tem como característica, assim como o CCDC, utilizar todas as imagens de entrada ao invés de composições. Também possui uma série de funções e parâmetros para a detecção de mudanças de pouca magnitude e de longo prazo, apresentando bons resultados na detecção de processos de degradação.
  
  \item \textbf{VerDET} - \textit{Vegetation Regeneration and Disturbance Estimates through Time} \citep{Hughes2017} - O VerDET funciona através da entrada de composições anuais sem nuvem com valores de reflectância de superfície que são segmentadas se baseando em técnicas de regressão utilizando redes neurais artificiais. Para cada pixel o slope é calculado e são posteriormente interpretados como áreas de distúrbio, estabilidade e regeneração, além de apresentar as magnitudes para a interpretação e classificação entre eventos rápidos ou lentos. Assim como o EWMACD, o VerDET também foi desenvolvido para trabalhar apenas com detecção de distúrbios em florestas.
  
  \item \textbf{MIICA} - \textit{Multi-index Integrated Change Analysis} \citep{JIN2013159} - Este algoritmo utiliza a composição de imagens sintéticas como entrada e tem como característica realizar sua análise baseado em limiares em invervalos bi-anuais. O MIICA analisa as mudanças espectrais de magnitude baseado nesses limiares utilizando quatro índices diferentes (NBR - \textit{Normalized Burn Ratio}, NDVI - \textit{Normalized Difference Vegetation Index}, \textit{Change Vector} e o \textit{Relative Change Vector Maximum}). Pode detectar mudanças relacionadas ao ganho e perda de biomassa e também a cenários de não mudança. É voltado para a detecão de grande magnitude e pode ser utilizado para a detecção de mudança em vários tipos de uso do solo.
  
  \item \textbf{ITRA} - \textit{Image Trends from Regression Analysis} \citep{VOGELMANN201292} É outro algoritmo que utiliza composições anuais sem nuvem geradas sinteticamente pelo CCDC. O ITRA ainda divide a série em três períodos e compara as mesmas com um modelo de regressão linear. É um algoritmo que tem como ênfase a detecção de distúrbios de longo período tanto em florestas como em áreas com vegetação arbustiva. Devido a sua característica de poder identificar mudanças de diferentes magnitudes, o ITRA pode ser utilizado detecção não só de distúrbios em florestas como também em outros tipos de vegetação.
  
  \item \textbf{Shapes-NBR} \citep{Meyer2013, Moisen2016} Como o nome já demonstra, este algoritmo funciona através da composição de uma série temporal de índices NBR, o que o difere de sua aplicação original, onde apenas um preditor de mudanças em áreas florestadas era utilizado e portanto chamado apenas de Shape \citep{SCHROEDER2017230}. O algoritmo funciona para cada pixel aplicando um método de regressão aditiva semi-paramétrico fornecendo uma trajetória suavizada restrita para se comportar de uma maneira ecologicamente sensível. Assim como o Landtrendr, este também gera resultados de acordo com as formas encontradas como o ano da detecção, magnitude da mudança, valores prévios à mudança e posteriores, assim como taxas de crescimento ou recuperação.
  
\end{itemize}

\subsection{Validação de Séries Temporais}
\hspace{13pt} O processo de validação de séries temporais se difere dos adotados em estudos de mapeamento de apenas uma ou poucas datas de estudo. Normalmente as amostras coletadas para validação são extraídas para apenas uma única data e comparada ao resultado obtido, no entanto, no caso do processamento de séries temporais, muitas datas ou até mesmo toda uma série de imagens deve ser utilizada como dado de entrada para os algoritmos preditores. Sendo assim, o método tradicional perde sua validade. É necessário analisar toda a série de imagens utilizada para entender os momentos de possível quebra e consequente detecção do distúrbio para podermos obter um resultado com maior precisão. Principalmente em situações onde houve distúrbios florestais que aconteceram em um determinado momento histórico e que posteriormente iniciaram um processo de regeneração natural ou então uma mudança para um terceiro uso do solo. Quanto maior a quantidade de tipos de mudança ocorridos durante o tempo analisado, maior a complexidade e consequente necessidade de utilização de métodos de validação apropriados.

Um dos métodos mais utilizados atualmente na validação de séries temporais, independentemente do algoritmo utilizado para a detecção das mudanças é o TimeSync \citep{COHEN20102911}.O TimeSync possui versão offline na qual possui uma interface gráfica onde é possível visualizar não somente uma imagem de uma única data, mas toda a série temporal tanto através de gráficos como através de miniaturas de imagens referentes a área mais próxima do pixel analisado. Além disso, após a implementação do algoritmo Landtrendr na plataforma Google Earth Engine, é possível exportar os dados para validação diretamente da plataforma online.  O TimeSync funciona recebendo uma lista de coordenadas na qual ele utiliza para exportar pequenas imagens com um \textit{buffer} da coordenada analisada para cada ano da série. O software utiliza uma interface gráfica para apresentar uma imagem por ano para cada coordenada e assim possibilitar que o pesquisador faça a validação visual de cada local ao longo do tempo. Os pontos de interesse para a validação são escolhidos pelo próprio usuário, preferencialmente de forma aleatória e estratificada de acordo com as classes utilizadas no mapeamento da série. As formas para a criação dos pontos aleatórios estratificados são diversas e podem ser feitas em um SIG assim como utilizando linguagens de programação através de bibliotecas especializadas. 
    
\subsection{Novas Perspectivas}
\hspace{13pt} Com a possibilidade de uso de diversos algoritmos e tipos de análise disponíveis, a escolha por um único método de análise pode ser problemática. Trabalhos desenvolvidos com o objetivo de comparação entre os algoritmos também podem ser problemáticos já que muitos dos algoritmos não se propõe exatamente ao mesmo tipo de análise. No entanto, é possível encontrar trabalhos que apresentam uma integração dos mesmos com o objetivo de encontrar o melhor resultado possível. O trabalho proposto por Sean Healey \citep{HEALEY2018717} buscou integrar todos os oito algoritmos citados neste trabalho junto a outros dados de entrada como o próprio conjunto de imagens com valores de reflectância da superfície, relevo e um mapa temático com os tipos de vegetação presente nas cenas. Todos os dados de entrada foram então processados e classificados utilizando o Random Forest \citep{Breiman2001}. Vários resultados foram gerados utilizando todos os dados de entrada assim como variações de combinação entre eles: resultados utilizando somente imagens Landsat, utilizando somente o resultado da combinação de todos os oito algoritmos preditivos, todos os algoritmos combinando as imagens Landsat, entre outros. O resultado que acabou representando a menor quantidade de erros foi justamente o que levou em consideração todos os dados de entrada possíveis.

Outro estudo ainda mais recente desenvolvido por \citep{BULLOCK2019111165} também buscou analisar distúrbios florestais integrando vários algoritmos apresentando ótimos resultados. Além disso, implementações feitas utilizando somente algoritmos com o Random Forest analisando séries temporais de imagens Landsat junto a camadas derivadas de estatísticas simples foram realizadas e também obtiveram resultados promissores \citep{WANG2019474}.
Estudos como os citados demonstram que apesar do bom resultado obtido individualmente, os algoritmos de detecção estudados possuem um potencial ainda maior de resultados ainda melhores quando integrados ou entre si e/ou utilizando técnicas híbridas. Além disso, não é possível dizer de forma objetiva que uma técnica seja melhor que outra. Cada uma apresenta pontos positivos e negativos dependendo do tipo de análise a ser realizada. No entanto, dentro os algoritmos analisados, o Landtrendr tem se mostrado a opção com implementação mais acessível e madura na plataforma do Google, o que possibilita uma maior democratização da técnica. Também é a solução que apresenta o maior número de erros de comissão e menor quantidade de omissão. A maior quantidade de eventos de comissão junto com uma baixa taxa de omissão se mostra promissora devido ao fato de que quase sempre é mais fácil limpar o resultado final removendo erros de comissão do que adicionar omissões.

\subsection{Conclusão}
\hspace{13pt} Ao analisar as opções de algoritmos disponíveis entendendo melhor suas características positivas e negativas, assim como outras possibilidades de implementação das análises de séries temporais de forma integrada, podemos compreender melhor o potencial da pesquisa na área. O desenvolvimento de soluções de monitoramento de distúrbios e de processos de degradação assim como de regeneração, restauração e conservação de áreas de interesse tem alavancado ainda mais a aplicabilidade dos acordos nacionais e internacionais que são mais do que nunca necessários para o desenvolvimento de políticas públicas que busquem resultados práticos. 

As aplicações destas tecnologias em ambientes tropicais ainda se encontra defasado quando comparado aos realizados em ambientes temperados, no entanto, o potencial para seu uso vem ampliando ao longo dos anos com o amadurecimento e ampliação do acesso a essas ferramentas em plataformas de uso livre como o Google Earth Engine. Sendo assim, a revisão de conceitos e potencial de aplicação das tecnologias apresentadas neste trabalho espera ter contribuído para uma atualização da comunidade científica em relação ao tema abordado.